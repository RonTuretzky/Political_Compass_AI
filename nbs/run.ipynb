{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "#| default_exp run\n",
    "#|  export\n",
    "from fastcore.script import call_parse\n",
    "def split_string(string):\n",
    "    # Removing the parentheses and splitting the string by comma\n",
    "    parts = string[1:-1].split(\",\")\n",
    "    # Removing the whitespace and quotes from the parts\n",
    "    parts = [part.strip().strip(\"'\") for part in parts]\n",
    "    return parts[0], parts[1]\n",
    "\n",
    "def return_iters(db:str # Path to db\n",
    "                 ):\n",
    "    train_iter = []\n",
    "    test_iter = []\n",
    "    file = open(db, 'r', encoding='latin1')\n",
    "    mapping = {\n",
    "        \"Libertarian Left\": 1,\n",
    "        \"Libertarian Right\": 2,\n",
    "        \"Authoritarian Left\": 3,\n",
    "        \"Authoritarian Right\": 4,\n",
    "        \"Centrist\": 5,\n",
    "        \"Authoritarian Center\": 6,\n",
    "        \"Left\": 7,\n",
    "        \"Right\": 8,\n",
    "        \"Libertarian Center\": 9,\n",
    "    }\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        opinion,text = split_string(line)\n",
    "        train_iter+=[(mapping[opinion],text)]\n",
    "        test_iter+=[(mapping[opinion],text)]\n",
    "    train_iter = iter(train_iter)\n",
    "    test_iter = iter(test_iter)\n",
    "    file.close()\n",
    "    return train_iter, test_iter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "#|  export\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "# from Political_Compass_AI.data_processing import return_iters\n",
    "# from Political_Compass_AI.data_processing import split_string\n",
    "from Political_Compass_AI.data_processing import yield_tokens\n",
    "from Political_Compass_AI.data_processing import collate_batch\n",
    "from Political_Compass_AI.model import TextClassificationModel\n",
    "from Political_Compass_AI.training import train\n",
    "from Political_Compass_AI.training import evaluate\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "def collate_batch(\n",
    "        batch\n",
    "):\n",
    "    global text_pipeline\n",
    "    global db\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    label_pipeline = lambda x: int(x) - 1\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
    "\n",
    "def run(\n",
    "    _db:str # dn path to run alignment distribution\n",
    "    ,emsize = 128\n",
    "    ,LR = 5\n",
    "    ,BATCH_SIZE = 32\n",
    "    ,optimizer = \"Adagrad\"\n",
    "    ,EPOCHS = 20\n",
    "\n",
    "\n",
    "):\n",
    "    global text_pipeline\n",
    "    global db\n",
    "    db=_db\n",
    "    tokenizer = get_tokenizer('basic_english')\n",
    "    text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "    label_pipeline = lambda x: int(x) - 1\n",
    "    train_iter, test_iter = return_iters(db)\n",
    "    vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    train_iter, test_iter = return_iters(db)\n",
    "    dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)\n",
    "    train_iter, test_iter = return_iters(db)\n",
    "    _num_class = len(set([label for (label, text) in train_iter]))\n",
    "    print(_num_class)\n",
    "    num_class = 9\n",
    "    vocab_size = len(vocab)\n",
    "    model = TextClassificationModel(vocab_size, emsize, num_class).to(device)\n",
    "    run_ledger = open(\"Run_Ledger.txt\", 'a')\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    _optimizer=optimizer\n",
    "    if optimizer==\"Adagrad\":\n",
    "        optimizer = torch.optim.Adagrad(model.parameters(), lr=LR)\n",
    "    elif optimizer==\"SGD\":\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "    else:\n",
    "        print(\"Choose a different optimizer\")\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "    total_accu = None\n",
    "    train_iter, test_iter = return_iters(db)\n",
    "    train_dataset = to_map_style_dataset(train_iter)\n",
    "    test_dataset = to_map_style_dataset(test_iter)\n",
    "    num_train = int(len(train_dataset) * 0.95)\n",
    "    split_train_, split_valid_ = \\\n",
    "        random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "    train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                                  shuffle=True, collate_fn=collate_batch)\n",
    "    valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                                  shuffle=True, collate_fn=collate_batch)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                                 shuffle=True, collate_fn=collate_batch)\n",
    "    first_flag = True\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(train_dataloader, model, optimizer, epoch)\n",
    "        accu_val = evaluate(valid_dataloader, model)\n",
    "        if total_accu is not None and total_accu > accu_val:\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            total_accu = accu_val\n",
    "\n",
    "        print('-' * 59)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "              'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                               time.time() - epoch_start_time,\n",
    "                                               accu_val))\n",
    "        print('-' * 59)\n",
    "\n",
    "    accu_test = evaluate(test_dataloader,model)\n",
    "\n",
    "    df_Log = {\"Database_file\":[],\"Epochs\":[],\"LR\":[],\"Batch_Size\":[],\n",
    "              \"Final_accu\":[],\"Optimzer\":[],\"accu_test\":[]}\n",
    "\n",
    "    df_Log[\"Database_file\"].append(db)\n",
    "    df_Log[\"Epochs\"].append(str(EPOCHS))\n",
    "    df_Log[\"LR\"].append( str(LR))\n",
    "    df_Log[\"Batch_Size\"].append(str(BATCH_SIZE))\n",
    "    df_Log[\"Final_accu\"].append(str(accu_val))\n",
    "    df_Log[\"Optimzer\"].append(_optimizer)\n",
    "    df_Log[\"accu_test\"].append(accu_test)\n",
    "\n",
    "    dataframe = pd.DataFrame(df_Log)\n",
    "    dataframe.to_csv('Run_Ledger.csv',mode='a', index=False,sep=\"\\t\")\n",
    "    print(str(accu_test))\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "7\n",
      "| epoch   1 |    50/  677 batches | accuracy    0.142\n",
      "| epoch   1 |   100/  677 batches | accuracy    0.175\n",
      "| epoch   1 |   150/  677 batches | accuracy    0.175\n",
      "| epoch   1 |   200/  677 batches | accuracy    0.203\n",
      "| epoch   1 |   250/  677 batches | accuracy    0.175\n",
      "| epoch   1 |   300/  677 batches | accuracy    0.133\n",
      "| epoch   1 |   350/  677 batches | accuracy    0.195\n",
      "| epoch   1 |   400/  677 batches | accuracy    0.180\n",
      "| epoch   1 |   450/  677 batches | accuracy    0.155\n",
      "| epoch   1 |   500/  677 batches | accuracy    0.185\n",
      "| epoch   1 |   550/  677 batches | accuracy    0.193\n",
      "| epoch   1 |   600/  677 batches | accuracy    0.122\n",
      "| epoch   1 |   650/  677 batches | accuracy    0.193\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  1.69s | valid accuracy    0.186 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |    50/  677 batches | accuracy    0.255\n",
      "| epoch   2 |   100/  677 batches | accuracy    0.247\n",
      "| epoch   2 |   150/  677 batches | accuracy    0.270\n",
      "| epoch   2 |   200/  677 batches | accuracy    0.280\n",
      "| epoch   2 |   250/  677 batches | accuracy    0.328\n",
      "| epoch   2 |   300/  677 batches | accuracy    0.263\n",
      "| epoch   2 |   350/  677 batches | accuracy    0.245\n",
      "| epoch   2 |   400/  677 batches | accuracy    0.253\n",
      "| epoch   2 |   450/  677 batches | accuracy    0.247\n",
      "| epoch   2 |   500/  677 batches | accuracy    0.255\n",
      "| epoch   2 |   550/  677 batches | accuracy    0.307\n",
      "| epoch   2 |   600/  677 batches | accuracy    0.260\n",
      "| epoch   2 |   650/  677 batches | accuracy    0.290\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  1.40s | valid accuracy    0.161 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |    50/  677 batches | accuracy    0.449\n",
      "| epoch   3 |   100/  677 batches | accuracy    0.485\n",
      "| epoch   3 |   150/  677 batches | accuracy    0.510\n",
      "| epoch   3 |   200/  677 batches | accuracy    0.505\n",
      "| epoch   3 |   250/  677 batches | accuracy    0.583\n",
      "| epoch   3 |   300/  677 batches | accuracy    0.550\n",
      "| epoch   3 |   350/  677 batches | accuracy    0.605\n",
      "| epoch   3 |   400/  677 batches | accuracy    0.600\n",
      "| epoch   3 |   450/  677 batches | accuracy    0.605\n",
      "| epoch   3 |   500/  677 batches | accuracy    0.568\n",
      "| epoch   3 |   550/  677 batches | accuracy    0.585\n",
      "| epoch   3 |   600/  677 batches | accuracy    0.623\n",
      "| epoch   3 |   650/  677 batches | accuracy    0.537\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  1.43s | valid accuracy    0.211 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |    50/  677 batches | accuracy    0.694\n",
      "| epoch   4 |   100/  677 batches | accuracy    0.698\n",
      "| epoch   4 |   150/  677 batches | accuracy    0.655\n",
      "| epoch   4 |   200/  677 batches | accuracy    0.657\n",
      "| epoch   4 |   250/  677 batches | accuracy    0.645\n",
      "| epoch   4 |   300/  677 batches | accuracy    0.613\n",
      "| epoch   4 |   350/  677 batches | accuracy    0.637\n",
      "| epoch   4 |   400/  677 batches | accuracy    0.655\n",
      "| epoch   4 |   450/  677 batches | accuracy    0.680\n",
      "| epoch   4 |   500/  677 batches | accuracy    0.665\n",
      "| epoch   4 |   550/  677 batches | accuracy    0.637\n",
      "| epoch   4 |   600/  677 batches | accuracy    0.685\n",
      "| epoch   4 |   650/  677 batches | accuracy    0.642\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  1.52s | valid accuracy    0.182 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |    50/  677 batches | accuracy    0.728\n",
      "| epoch   5 |   100/  677 batches | accuracy    0.705\n",
      "| epoch   5 |   150/  677 batches | accuracy    0.723\n",
      "| epoch   5 |   200/  677 batches | accuracy    0.750\n",
      "| epoch   5 |   250/  677 batches | accuracy    0.765\n",
      "| epoch   5 |   300/  677 batches | accuracy    0.755\n",
      "| epoch   5 |   350/  677 batches | accuracy    0.735\n",
      "| epoch   5 |   400/  677 batches | accuracy    0.740\n",
      "| epoch   5 |   450/  677 batches | accuracy    0.730\n",
      "| epoch   5 |   500/  677 batches | accuracy    0.733\n",
      "| epoch   5 |   550/  677 batches | accuracy    0.795\n",
      "| epoch   5 |   600/  677 batches | accuracy    0.760\n",
      "| epoch   5 |   650/  677 batches | accuracy    0.665\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  1.55s | valid accuracy    0.193 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |    50/  677 batches | accuracy    0.779\n",
      "| epoch   6 |   100/  677 batches | accuracy    0.713\n",
      "| epoch   6 |   150/  677 batches | accuracy    0.730\n",
      "| epoch   6 |   200/  677 batches | accuracy    0.777\n",
      "| epoch   6 |   250/  677 batches | accuracy    0.710\n",
      "| epoch   6 |   300/  677 batches | accuracy    0.765\n",
      "| epoch   6 |   350/  677 batches | accuracy    0.743\n",
      "| epoch   6 |   400/  677 batches | accuracy    0.718\n",
      "| epoch   6 |   450/  677 batches | accuracy    0.755\n",
      "| epoch   6 |   500/  677 batches | accuracy    0.762\n",
      "| epoch   6 |   550/  677 batches | accuracy    0.782\n",
      "| epoch   6 |   600/  677 batches | accuracy    0.810\n",
      "| epoch   6 |   650/  677 batches | accuracy    0.738\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time:  1.49s | valid accuracy    0.193 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |    50/  677 batches | accuracy    0.738\n",
      "| epoch   7 |   100/  677 batches | accuracy    0.780\n",
      "| epoch   7 |   150/  677 batches | accuracy    0.735\n",
      "| epoch   7 |   200/  677 batches | accuracy    0.725\n",
      "| epoch   7 |   250/  677 batches | accuracy    0.738\n",
      "| epoch   7 |   300/  677 batches | accuracy    0.767\n",
      "| epoch   7 |   350/  677 batches | accuracy    0.772\n",
      "| epoch   7 |   400/  677 batches | accuracy    0.745\n",
      "| epoch   7 |   450/  677 batches | accuracy    0.760\n",
      "| epoch   7 |   500/  677 batches | accuracy    0.735\n",
      "| epoch   7 |   550/  677 batches | accuracy    0.757\n",
      "| epoch   7 |   600/  677 batches | accuracy    0.728\n",
      "| epoch   7 |   650/  677 batches | accuracy    0.755\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time:  1.58s | valid accuracy    0.193 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |    50/  677 batches | accuracy    0.735\n",
      "| epoch   8 |   100/  677 batches | accuracy    0.762\n",
      "| epoch   8 |   150/  677 batches | accuracy    0.745\n",
      "| epoch   8 |   200/  677 batches | accuracy    0.772\n",
      "| epoch   8 |   250/  677 batches | accuracy    0.775\n",
      "| epoch   8 |   300/  677 batches | accuracy    0.770\n",
      "| epoch   8 |   350/  677 batches | accuracy    0.725\n",
      "| epoch   8 |   400/  677 batches | accuracy    0.765\n",
      "| epoch   8 |   450/  677 batches | accuracy    0.740\n",
      "| epoch   8 |   500/  677 batches | accuracy    0.750\n",
      "| epoch   8 |   550/  677 batches | accuracy    0.740\n",
      "| epoch   8 |   600/  677 batches | accuracy    0.728\n",
      "| epoch   8 |   650/  677 batches | accuracy    0.738\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time:  1.53s | valid accuracy    0.193 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |    50/  677 batches | accuracy    0.735\n",
      "| epoch   9 |   100/  677 batches | accuracy    0.708\n",
      "| epoch   9 |   150/  677 batches | accuracy    0.750\n",
      "| epoch   9 |   200/  677 batches | accuracy    0.743\n",
      "| epoch   9 |   250/  677 batches | accuracy    0.748\n",
      "| epoch   9 |   300/  677 batches | accuracy    0.728\n",
      "| epoch   9 |   350/  677 batches | accuracy    0.777\n",
      "| epoch   9 |   400/  677 batches | accuracy    0.757\n",
      "| epoch   9 |   450/  677 batches | accuracy    0.738\n",
      "| epoch   9 |   500/  677 batches | accuracy    0.785\n",
      "| epoch   9 |   550/  677 batches | accuracy    0.743\n",
      "| epoch   9 |   600/  677 batches | accuracy    0.765\n",
      "| epoch   9 |   650/  677 batches | accuracy    0.755\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time:  1.62s | valid accuracy    0.193 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |    50/  677 batches | accuracy    0.735\n",
      "| epoch  10 |   100/  677 batches | accuracy    0.772\n",
      "| epoch  10 |   150/  677 batches | accuracy    0.745\n",
      "| epoch  10 |   200/  677 batches | accuracy    0.762\n",
      "| epoch  10 |   250/  677 batches | accuracy    0.748\n",
      "| epoch  10 |   300/  677 batches | accuracy    0.765\n",
      "| epoch  10 |   350/  677 batches | accuracy    0.760\n",
      "| epoch  10 |   400/  677 batches | accuracy    0.738\n",
      "| epoch  10 |   450/  677 batches | accuracy    0.748\n",
      "| epoch  10 |   500/  677 batches | accuracy    0.757\n",
      "| epoch  10 |   550/  677 batches | accuracy    0.772\n",
      "| epoch  10 |   600/  677 batches | accuracy    0.730\n",
      "| epoch  10 |   650/  677 batches | accuracy    0.725\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time:  1.56s | valid accuracy    0.193 \n",
      "-----------------------------------------------------------\n",
      "| epoch  11 |    50/  677 batches | accuracy    0.809\n",
      "| epoch  11 |   100/  677 batches | accuracy    0.720\n",
      "| epoch  11 |   150/  677 batches | accuracy    0.748\n",
      "| epoch  11 |   200/  677 batches | accuracy    0.708\n",
      "| epoch  11 |   250/  677 batches | accuracy    0.745\n",
      "| epoch  11 |   300/  677 batches | accuracy    0.760\n",
      "| epoch  11 |   350/  677 batches | accuracy    0.755\n",
      "| epoch  11 |   400/  677 batches | accuracy    0.777\n",
      "| epoch  11 |   450/  677 batches | accuracy    0.757\n",
      "| epoch  11 |   500/  677 batches | accuracy    0.752\n",
      "| epoch  11 |   550/  677 batches | accuracy    0.740\n",
      "| epoch  11 |   600/  677 batches | accuracy    0.760\n",
      "| epoch  11 |   650/  677 batches | accuracy    0.743\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  11 | time:  1.56s | valid accuracy    0.193 \n",
      "-----------------------------------------------------------\n",
      "| epoch  12 |    50/  677 batches | accuracy    0.779\n",
      "| epoch  12 |   100/  677 batches | accuracy    0.745\n",
      "| epoch  12 |   150/  677 batches | accuracy    0.755\n",
      "| epoch  12 |   200/  677 batches | accuracy    0.767\n",
      "| epoch  12 |   250/  677 batches | accuracy    0.735\n",
      "| epoch  12 |   300/  677 batches | accuracy    0.757\n",
      "| epoch  12 |   350/  677 batches | accuracy    0.743\n",
      "| epoch  12 |   400/  677 batches | accuracy    0.760\n",
      "| epoch  12 |   450/  677 batches | accuracy    0.752\n",
      "| epoch  12 |   500/  677 batches | accuracy    0.760\n",
      "| epoch  12 |   550/  677 batches | accuracy    0.740\n",
      "| epoch  12 |   600/  677 batches | accuracy    0.728\n",
      "| epoch  12 |   650/  677 batches | accuracy    0.728\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  12 | time:  1.55s | valid accuracy    0.193 \n",
      "-----------------------------------------------------------\n",
      "| epoch  13 |    50/  677 batches | accuracy    0.728\n",
      "| epoch  13 |   100/  677 batches | accuracy    0.797\n",
      "| epoch  13 |   150/  677 batches | accuracy    0.752\n",
      "| epoch  13 |   200/  677 batches | accuracy    0.720\n",
      "| epoch  13 |   250/  677 batches | accuracy    0.750\n",
      "| epoch  13 |   300/  677 batches | accuracy    0.757\n",
      "| epoch  13 |   350/  677 batches | accuracy    0.787\n",
      "| epoch  13 |   400/  677 batches | accuracy    0.725\n",
      "| epoch  13 |   450/  677 batches | accuracy    0.740\n",
      "| epoch  13 |   500/  677 batches | accuracy    0.743\n",
      "| epoch  13 |   550/  677 batches | accuracy    0.752\n",
      "| epoch  13 |   600/  677 batches | accuracy    0.775\n",
      "| epoch  13 |   650/  677 batches | accuracy    0.738\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  13 | time:  1.54s | valid accuracy    0.193 \n",
      "-----------------------------------------------------------\n",
      "| epoch  14 |    50/  677 batches | accuracy    0.789\n",
      "| epoch  14 |   100/  677 batches | accuracy    0.752\n",
      "| epoch  14 |   150/  677 batches | accuracy    0.720\n",
      "| epoch  14 |   200/  677 batches | accuracy    0.715\n",
      "| epoch  14 |   250/  677 batches | accuracy    0.755\n",
      "| epoch  14 |   300/  677 batches | accuracy    0.743\n",
      "| epoch  14 |   350/  677 batches | accuracy    0.770\n",
      "| epoch  14 |   400/  677 batches | accuracy    0.772\n",
      "| epoch  14 |   450/  677 batches | accuracy    0.770\n",
      "| epoch  14 |   500/  677 batches | accuracy    0.740\n",
      "| epoch  14 |   550/  677 batches | accuracy    0.740\n",
      "| epoch  14 |   600/  677 batches | accuracy    0.755\n",
      "| epoch  14 |   650/  677 batches | accuracy    0.738\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  14 | time:  1.53s | valid accuracy    0.193 \n",
      "-----------------------------------------------------------\n",
      "| epoch  15 |    50/  677 batches | accuracy    0.765\n",
      "| epoch  15 |   100/  677 batches | accuracy    0.703\n",
      "| epoch  15 |   150/  677 batches | accuracy    0.787\n",
      "| epoch  15 |   200/  677 batches | accuracy    0.760\n",
      "| epoch  15 |   250/  677 batches | accuracy    0.755\n",
      "| epoch  15 |   300/  677 batches | accuracy    0.765\n",
      "| epoch  15 |   350/  677 batches | accuracy    0.767\n",
      "| epoch  15 |   400/  677 batches | accuracy    0.733\n",
      "| epoch  15 |   450/  677 batches | accuracy    0.728\n",
      "| epoch  15 |   500/  677 batches | accuracy    0.733\n",
      "| epoch  15 |   550/  677 batches | accuracy    0.733\n",
      "| epoch  15 |   600/  677 batches | accuracy    0.787\n",
      "| epoch  15 |   650/  677 batches | accuracy    0.770\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  15 | time:  1.53s | valid accuracy    0.193 \n",
      "-----------------------------------------------------------\n",
      "| epoch  16 |    50/  677 batches | accuracy    0.743\n",
      "| epoch  16 |   100/  677 batches | accuracy    0.760\n",
      "| epoch  16 |   150/  677 batches | accuracy    0.725\n",
      "| epoch  16 |   200/  677 batches | accuracy    0.787\n",
      "| epoch  16 |   250/  677 batches | accuracy    0.740\n",
      "| epoch  16 |   300/  677 batches | accuracy    0.750\n",
      "| epoch  16 |   350/  677 batches | accuracy    0.738\n",
      "| epoch  16 |   400/  677 batches | accuracy    0.703\n",
      "| epoch  16 |   450/  677 batches | accuracy    0.755\n",
      "| epoch  16 |   500/  677 batches | accuracy    0.780\n",
      "| epoch  16 |   550/  677 batches | accuracy    0.772\n",
      "| epoch  16 |   600/  677 batches | accuracy    0.757\n",
      "| epoch  16 |   650/  677 batches | accuracy    0.748\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  16 | time:  1.53s | valid accuracy    0.193 \n",
      "-----------------------------------------------------------\n",
      "| epoch  17 |    50/  677 batches | accuracy    0.779\n",
      "| epoch  17 |   100/  677 batches | accuracy    0.733\n",
      "| epoch  17 |   150/  677 batches | accuracy    0.755\n",
      "| epoch  17 |   200/  677 batches | accuracy    0.770\n",
      "| epoch  17 |   250/  677 batches | accuracy    0.745\n",
      "| epoch  17 |   300/  677 batches | accuracy    0.795\n",
      "| epoch  17 |   350/  677 batches | accuracy    0.743\n",
      "| epoch  17 |   400/  677 batches | accuracy    0.740\n",
      "| epoch  17 |   450/  677 batches | accuracy    0.752\n",
      "| epoch  17 |   500/  677 batches | accuracy    0.752\n",
      "| epoch  17 |   550/  677 batches | accuracy    0.728\n",
      "| epoch  17 |   600/  677 batches | accuracy    0.698\n",
      "| epoch  17 |   650/  677 batches | accuracy    0.762\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  17 | time:  1.52s | valid accuracy    0.193 \n",
      "-----------------------------------------------------------\n",
      "| epoch  18 |    50/  677 batches | accuracy    0.765\n",
      "| epoch  18 |   100/  677 batches | accuracy    0.760\n",
      "| epoch  18 |   150/  677 batches | accuracy    0.757\n",
      "| epoch  18 |   200/  677 batches | accuracy    0.743\n",
      "| epoch  18 |   250/  677 batches | accuracy    0.790\n",
      "| epoch  18 |   300/  677 batches | accuracy    0.762\n",
      "| epoch  18 |   350/  677 batches | accuracy    0.745\n",
      "| epoch  18 |   400/  677 batches | accuracy    0.743\n",
      "| epoch  18 |   450/  677 batches | accuracy    0.715\n",
      "| epoch  18 |   500/  677 batches | accuracy    0.767\n",
      "| epoch  18 |   550/  677 batches | accuracy    0.765\n",
      "| epoch  18 |   600/  677 batches | accuracy    0.723\n",
      "| epoch  18 |   650/  677 batches | accuracy    0.725\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  18 | time:  1.54s | valid accuracy    0.193 \n",
      "-----------------------------------------------------------\n",
      "| epoch  19 |    50/  677 batches | accuracy    0.745\n",
      "| epoch  19 |   100/  677 batches | accuracy    0.745\n",
      "| epoch  19 |   150/  677 batches | accuracy    0.745\n",
      "| epoch  19 |   200/  677 batches | accuracy    0.745\n",
      "| epoch  19 |   250/  677 batches | accuracy    0.745\n",
      "| epoch  19 |   300/  677 batches | accuracy    0.777\n",
      "| epoch  19 |   350/  677 batches | accuracy    0.780\n",
      "| epoch  19 |   400/  677 batches | accuracy    0.743\n",
      "| epoch  19 |   450/  677 batches | accuracy    0.738\n",
      "| epoch  19 |   500/  677 batches | accuracy    0.767\n",
      "| epoch  19 |   550/  677 batches | accuracy    0.775\n",
      "| epoch  19 |   600/  677 batches | accuracy    0.728\n",
      "| epoch  19 |   650/  677 batches | accuracy    0.740\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  19 | time:  1.60s | valid accuracy    0.193 \n",
      "-----------------------------------------------------------\n",
      "| epoch  20 |    50/  677 batches | accuracy    0.775\n",
      "| epoch  20 |   100/  677 batches | accuracy    0.748\n",
      "| epoch  20 |   150/  677 batches | accuracy    0.740\n",
      "| epoch  20 |   200/  677 batches | accuracy    0.738\n",
      "| epoch  20 |   250/  677 batches | accuracy    0.775\n",
      "| epoch  20 |   300/  677 batches | accuracy    0.740\n",
      "| epoch  20 |   350/  677 batches | accuracy    0.740\n",
      "| epoch  20 |   400/  677 batches | accuracy    0.730\n",
      "| epoch  20 |   450/  677 batches | accuracy    0.760\n",
      "| epoch  20 |   500/  677 batches | accuracy    0.777\n",
      "| epoch  20 |   550/  677 batches | accuracy    0.743\n",
      "| epoch  20 |   600/  677 batches | accuracy    0.748\n",
      "| epoch  20 |   650/  677 batches | accuracy    0.738\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  20 | time:  1.56s | valid accuracy    0.193 \n",
      "-----------------------------------------------------------\n",
      "0.7224561403508772\n"
     ]
    }
   ],
   "source": [
    "model =run(\"../9_aligns_merged\",BATCH_SIZE=8)\n",
    "#torch.save(model.state_dict(), <path_to>)\n",
    "# model.load_state_dict(torch.load(<path_to>))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Libertarian Right comment\n"
     ]
    }
   ],
   "source": [
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item() + 1\n",
    "mapping = {\n",
    "        1:\"Libertarian Left\",\n",
    "        2: \"Libertarian Right\",\n",
    "        3:\"Authoritarian Left\" ,\n",
    "        4: \"Authoritarian Right\",\n",
    "        5: \"Centrist\",\n",
    "         6:\"Authoritarian Center\",\n",
    "        7: \"Left\",\n",
    "        8: \"Right\",\n",
    "        9:\"Libertarian Center\" ,\n",
    "    }\n",
    "model = model.to(\"cpu\")\n",
    "ex_text_str = \"\"\"\n",
    "People didn't even think he was going to invade to begin with, what are you talking about? ðŸ˜…\n",
    "And I have no idea how much European support is carrying Ukraine here vs how effective the Ukrainian resistance is (and how fucking shite the Russian offence is).\n",
    "'Nyhow. Not really relevant. Putin has to be stopped, the war has to end. Aid should be provided to Ukraine. And at the very least, your Socialist Party isn't literally simping for Putin.\n",
    "Which many Communist parties around the world are doing.\n",
    "I just tried to explain why they might do that.\n",
    "Because you called them \"nuts\".\n",
    "There's good reasons not to trust NATO or the U.S. I hope time won't prove me correct, but it is naÃ¯ve to assume that America's already hyper-conservative neoliberal approach cannot slide further right.\n",
    "For the record, I also don't think the U.S is doing anything inherently bad in terms of helping Ukraine (unlike what someone like Jimmy Dore might spin).\n",
    "\"\"\"\n",
    "print(\"This is a %s comment\" % mapping[predict(ex_text_str, text_pipeline)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
